{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "957dcda9",
   "metadata": {},
   "source": [
    "# Version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b835a266",
   "metadata": {},
   "source": [
    "# Please read this to understand the considerations of the Experiment\n",
    "\n",
    "#### 1) In this experement the null values above 70% are dropped(for whole dataset). \n",
    "#### 2) For numerical features median is used to fill/handle the null values.\n",
    "#### 3) 'REC_ID', 'HRPOSTMED', 'PDMEDTM', 'EVENT_ID', 'Unnamed:0', 'PDMEDDT', 'EXAMDT', 'PDSTATE', 'EXAMTM', 'INFODT' ,  'PDTRTMNT', 'ORIG_ENTRY',  'LAST_UPDATE'  These columns are dropped from the dataset\n",
    "\n",
    "#### 4) pd.get_dummies(df_new) is used for encoding\n",
    "\n",
    "#### 5) Finally for model traning various machine learning techniques are used to get the best model for this usecase\n",
    "\n",
    "#### 6) It is observed that Gaussian Naive Bayes (GaussianNB) has highest accuracy of 87% out of all the models used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da796c0",
   "metadata": {},
   "source": [
    "## For your Experiment\n",
    "1) please use different ways of filling null values\n",
    "\n",
    "2) Try handling the \"PDSTATE\" column and add that also with the dataset for traning (Siwani did by dropping the null values from entire dataset, which resulted in less dimention of the dataset / loss of many rows and information) However her model achived 78% accuracy\n",
    "\n",
    "3) Try using mode to fill the null values ( as i have used median )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19d1907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8af5149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"MDS-UPDRS_Part_III-Group-A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f174ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalised = df.replace(101.,0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3199cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>REC_ID</th>\n",
       "      <th>PATNO</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>PAG_NAME</th>\n",
       "      <th>INFODT</th>\n",
       "      <th>PDTRTMNT</th>\n",
       "      <th>PDSTATE</th>\n",
       "      <th>HRPOSTMED</th>\n",
       "      <th>PDMEDYN</th>\n",
       "      <th>...</th>\n",
       "      <th>NP3RTALU</th>\n",
       "      <th>NP3RTARL</th>\n",
       "      <th>NP3RTALL</th>\n",
       "      <th>NP3RTALJ</th>\n",
       "      <th>NP3RTCON</th>\n",
       "      <th>NP3TOT</th>\n",
       "      <th>DYSKPRES</th>\n",
       "      <th>NHY</th>\n",
       "      <th>ORIG_ENTRY</th>\n",
       "      <th>LAST_UPDATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17595</td>\n",
       "      <td>671077401</td>\n",
       "      <td>57869</td>\n",
       "      <td>V04</td>\n",
       "      <td>NUPDRS3</td>\n",
       "      <td>12/2017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OFF</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>01/2018</td>\n",
       "      <td>2018-01-11 15:46:02.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21551</td>\n",
       "      <td>IANT214603</td>\n",
       "      <td>111429</td>\n",
       "      <td>BL</td>\n",
       "      <td>NUPDRDOSE3</td>\n",
       "      <td>11/2022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12/2022</td>\n",
       "      <td>2022-12-20 00:00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23302</td>\n",
       "      <td>IANT310558</td>\n",
       "      <td>182340</td>\n",
       "      <td>BL</td>\n",
       "      <td>NUPDRDOSE3</td>\n",
       "      <td>02/2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>08/2023</td>\n",
       "      <td>2023-08-09 00:00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20789</td>\n",
       "      <td>IAON164829</td>\n",
       "      <td>101018</td>\n",
       "      <td>V02</td>\n",
       "      <td>NUPDRDOSE3</td>\n",
       "      <td>11/2021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>3.0833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11/2021</td>\n",
       "      <td>2021-11-16 00:00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16024</td>\n",
       "      <td>IANT163527</td>\n",
       "      <td>52587</td>\n",
       "      <td>V12</td>\n",
       "      <td>NUPDRDOSE3</td>\n",
       "      <td>04/2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>05/2021</td>\n",
       "      <td>2021-05-04 00:00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11959</th>\n",
       "      <td>13792</td>\n",
       "      <td>608662801</td>\n",
       "      <td>41967</td>\n",
       "      <td>V04</td>\n",
       "      <td>NUPDRS3</td>\n",
       "      <td>12/2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OFF</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12/2016</td>\n",
       "      <td>2020-06-24 10:08:10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11960</th>\n",
       "      <td>21263</td>\n",
       "      <td>IANT275548</td>\n",
       "      <td>102366</td>\n",
       "      <td>V05</td>\n",
       "      <td>NUPDRDOSE3</td>\n",
       "      <td>06/2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>06/2023</td>\n",
       "      <td>2023-06-01 00:00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11961</th>\n",
       "      <td>1171</td>\n",
       "      <td>741604401</td>\n",
       "      <td>3112</td>\n",
       "      <td>V15</td>\n",
       "      <td>NUPDRS3</td>\n",
       "      <td>05/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>05/2019</td>\n",
       "      <td>2020-05-29 13:17:08.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11962</th>\n",
       "      <td>18334</td>\n",
       "      <td>IANT164157</td>\n",
       "      <td>59733</td>\n",
       "      <td>R08</td>\n",
       "      <td>NUPDRDOSE3</td>\n",
       "      <td>06/2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>06/2021</td>\n",
       "      <td>2021-06-22 00:00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11963</th>\n",
       "      <td>8926</td>\n",
       "      <td>468805101</td>\n",
       "      <td>3916</td>\n",
       "      <td>V05</td>\n",
       "      <td>NUPDRS3</td>\n",
       "      <td>10/2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10/2014</td>\n",
       "      <td>2014-10-24 08:09:36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11964 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      REC_ID   PATNO EVENT_ID    PAG_NAME   INFODT  PDTRTMNT  \\\n",
       "0           17595   671077401   57869      V04     NUPDRS3  12/2017       1.0   \n",
       "1           21551  IANT214603  111429       BL  NUPDRDOSE3  11/2022       0.0   \n",
       "2           23302  IANT310558  182340       BL  NUPDRDOSE3  02/2023       0.0   \n",
       "3           20789  IAON164829  101018      V02  NUPDRDOSE3  11/2021       1.0   \n",
       "4           16024  IANT163527   52587      V12  NUPDRDOSE3  04/2021       0.0   \n",
       "...           ...         ...     ...      ...         ...      ...       ...   \n",
       "11959       13792   608662801   41967      V04     NUPDRS3  12/2016       1.0   \n",
       "11960       21263  IANT275548  102366      V05  NUPDRDOSE3  06/2023       0.0   \n",
       "11961        1171   741604401    3112      V15     NUPDRS3  05/2019       0.0   \n",
       "11962       18334  IANT164157   59733      R08  NUPDRDOSE3  06/2021       0.0   \n",
       "11963        8926   468805101    3916      V05     NUPDRS3  10/2014       1.0   \n",
       "\n",
       "      PDSTATE  HRPOSTMED  PDMEDYN  ...  NP3RTALU NP3RTARL NP3RTALL NP3RTALJ  \\\n",
       "0         OFF    14.5000      1.0  ...       1.0      2.0      3.0      0.0   \n",
       "1         NaN        NaN      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "2         NaN        NaN      0.0  ...       1.0      0.0      0.0      0.0   \n",
       "3          ON     3.0833      1.0  ...       0.0      0.0      0.0      0.0   \n",
       "4         NaN        NaN      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "...       ...        ...      ...  ...       ...      ...      ...      ...   \n",
       "11959     OFF    15.0000      1.0  ...       0.0      0.0      1.0      0.0   \n",
       "11960     NaN        NaN      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "11961     NaN        NaN      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "11962     NaN        NaN      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "11963      ON     2.5000      1.0  ...       0.0      0.0      0.0      2.0   \n",
       "\n",
       "      NP3RTCON  NP3TOT  DYSKPRES  NHY  ORIG_ENTRY            LAST_UPDATE  \n",
       "0          0.0    54.0       0.0  2.0     01/2018  2018-01-11 15:46:02.0  \n",
       "1          0.0     0.0       0.0  0.0     12/2022  2022-12-20 00:00:00.0  \n",
       "2          1.0    16.0       0.0  1.0     08/2023  2023-08-09 00:00:00.0  \n",
       "3          0.0    15.0       0.0  2.0     11/2021  2021-11-16 00:00:00.0  \n",
       "4          0.0     0.0       0.0  0.0     05/2021  2021-05-04 00:00:00.0  \n",
       "...        ...     ...       ...  ...         ...                    ...  \n",
       "11959      1.0     7.0       0.0  0.0     12/2016  2020-06-24 10:08:10.0  \n",
       "11960      0.0     4.0       0.0  0.0     06/2023  2023-06-01 00:00:00.0  \n",
       "11961      0.0     2.0       0.0  0.0     05/2019  2020-05-29 13:17:08.0  \n",
       "11962      0.0     NaN       0.0  0.0     06/2021  2021-06-22 00:00:00.0  \n",
       "11963      3.0    28.0       0.0  2.0     10/2014  2014-10-24 08:09:36.0  \n",
       "\n",
       "[11964 rows x 53 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 70  # Set the threshold for missing values percentage\n",
    "\n",
    "# Calculate the percentage of missing values for each column\n",
    "null_values = df_normalised.isna().mean() * 100\n",
    "\n",
    "# Identify columns with missing values greater than the threshold\n",
    "columns_to_drop = null_values[null_values > threshold].index\n",
    "\n",
    "# Drop the identified columns\n",
    "df_normalised = df_normalised.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display the DataFrame after dropping columns\n",
    "df_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee92a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7480eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns with missing values\n",
    "numerical_columns_with_missing = df_normalised.select_dtypes(include='number').columns[df_normalised.select_dtypes(include='number').isnull().any()]\n",
    "\n",
    "# Replace missing values with median for each numerical column\n",
    "for column in numerical_columns_with_missing:\n",
    "    median_value = df_normalised[column].median()  #Try using mode to see the change \n",
    "    df_normalised[column].fillna(median_value, inplace=True)\n",
    "\n",
    "    \n",
    "# Filling the null values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8e339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf054f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_normalised.drop(['REC_ID','HRPOSTMED','PDMEDTM','EVENT_ID','Unnamed: 0','PDMEDDT','EXAMDT','PDSTATE','EXAMTM','INFODT', 'PDTRTMNT','ORIG_ENTRY', 'LAST_UPDATE'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ea8320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.get_dummies(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d21a5f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PATNO', 'PDMEDYN', 'DBSYN', 'NP3SPCH', 'NP3FACXP', 'NP3RIGN',\n",
       "       'NP3RIGRU', 'NP3RIGLU', 'NP3RIGRL', 'NP3RIGLL', 'NP3FTAPR', 'NP3FTAPL',\n",
       "       'NP3HMOVR', 'NP3HMOVL', 'NP3PRSPR', 'NP3PRSPL', 'NP3TTAPR', 'NP3TTAPL',\n",
       "       'NP3LGAGR', 'NP3LGAGL', 'NP3RISNG', 'NP3GAIT', 'NP3FRZGT', 'NP3PSTBL',\n",
       "       'NP3POSTR', 'NP3BRADY', 'NP3PTRMR', 'NP3PTRML', 'NP3KTRMR', 'NP3KTRML',\n",
       "       'NP3RTARU', 'NP3RTALU', 'NP3RTARL', 'NP3RTALL', 'NP3RTALJ', 'NP3RTCON',\n",
       "       'NP3TOT', 'DYSKPRES', 'NHY', 'PAG_NAME_NUPDR3OF', 'PAG_NAME_NUPDR3ON',\n",
       "       'PAG_NAME_NUPDRDOSE3', 'PAG_NAME_NUPDRS3', 'PAG_NAME_NUPDRS3A'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7997b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_new, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e382408",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train.drop('NHY',axis=1)\n",
    "y_train=train['NHY']\n",
    "\n",
    "x_test=test.drop('NHY',axis=1)\n",
    "y_test=test['NHY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f28eb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8374, 43)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79449a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utkar\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7958217270194986\n",
      "0.7426183844011142\n",
      "0.6746518105849583\n",
      "0.8774373259052924\n",
      "0.6749303621169916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#from sklearn.metrics import precision_score,recall_score, f1_score, accuracy_score\n",
    "model1 = DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = LogisticRegression()\n",
    "model4 = GradientBoostingClassifier()\n",
    "gnb = GaussianNB().fit(x_train, y_train) \n",
    "\n",
    "model1.fit(x_train,y_train)\n",
    "model2.fit(x_train,y_train)\n",
    "model3.fit(x_train,y_train)\n",
    "model4.fit(x_train,y_train)\n",
    "\n",
    "gnb_predictions = gnb.predict(x_test) \n",
    "pred1=model1.predict_proba(x_test)\n",
    "pred2=model2.predict_proba(x_test)\n",
    "pred3=model3.predict_proba(x_test)\n",
    "pred4=model4.predict_proba(x_test)\n",
    "\n",
    "accuracy = gnb.score(x_test, y_test) \n",
    "sc1 = model1.score(x_test,y_test)\n",
    "sc2 = model2.score(x_test,y_test)\n",
    "sc3 = model3.score(x_test,y_test)\n",
    "sc4 = model4.score(x_test,y_test)\n",
    "\n",
    "print(sc1)\n",
    "print(sc2)\n",
    "print(sc3)\n",
    "print(sc4) #Gaussian Naive Bayes (GaussianNB)\n",
    "print(accuracy) \n",
    "\n",
    "\n",
    "finalpred = (pred1+pred2+pred3)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9fad4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "ANN_model = tf.keras.models.Sequential()\n",
    "ANN_model.add(tf.keras.layers.Dense(units=400, activation='relu', input_shape=(43, )))\n",
    "ANN_model.add(tf.keras.layers.Dropout(0.2))\n",
    "ANN_model.add(tf.keras.layers.Dense(units=400, activation='relu'))\n",
    "ANN_model.add(tf.keras.layers.Dropout(0.2))\n",
    "ANN_model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e5058be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model.compile(optimizer='Adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98ed0ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "262/262 [==============================] - 2s 3ms/step - loss: nan - accuracy: 0.3294\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.3304\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.3304\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.3304\n",
      "Epoch 5/10\n",
      "262/262 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.3304\n",
      "Epoch 6/10\n",
      "262/262 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.3304\n",
      "Epoch 7/10\n",
      "262/262 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.3304\n",
      "Epoch 8/10\n",
      "262/262 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.3304\n",
      "Epoch 9/10\n",
      "262/262 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.3304\n",
      "Epoch 10/10\n",
      "262/262 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.3304\n"
     ]
    }
   ],
   "source": [
    "epochs_hist = ANN_model.fit(x_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "676a8994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\utkar\\anaconda3\\envs\\tfgpu\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\utkar\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from xgboost) (1.5.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\utkar\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from xgboost) (1.19.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\utkar\\anaconda3\\envs\\tfgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\utkar\\anaconda3\\envs\\tfgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\utkar\\anaconda3\\envs\\tfgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\utkar\\anaconda3\\envs\\tfgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\utkar\\anaconda3\\envs\\tfgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\utkar\\anaconda3\\envs\\tfgpu\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "288181bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:42:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utkar\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=10, n_jobs=16,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "XGB_model = xgb.XGBClassifier(learning_rate = 0.1, max_depth = 5, n_estimators = 10)\n",
    "XGB_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c37038c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8384401114206128\n"
     ]
    }
   ],
   "source": [
    "result_train = XGB_model.score(x_test,y_test)\n",
    "print(\"Accuracy : {}\".format(result_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f881e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785cd389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
